---
title: 单机如何支撑百万连接
date: 2022-11-03 11:08:50
permalink: /note/fwkLab/millionConnection/
categories:
  - 架构
  - 实验室
tags:
  - Netty
author: 
  name: Orochi
  #link: https://github.com/kevin
---
# **单机如何支撑百万连接**

## 服务器配置

- **系统**：Ubuntu 16.04
- **配置**：4核8G 磁盘100G
- **分区**：/   剩余所有，boot 1G，swap 8G
- **台数**：1台

## 客户端配置
- **系统**：Ubuntu 16.04
- **配置**：1核512M 磁盘20G
- **分区**：/   剩余所有，boot 200M，swap 512M
- **台数**：5台

## 固定IP
### 1.修改配置

```bash
sudo vim /etc/network/interfaces
```



### 2.服务端IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.222

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```



### 3.客户端1 IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.223

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:1

iface ens32:1 inet static

address 10.66.11.224

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:2

iface ens32:2 inet static

address 10.66.11.225

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:3

iface ens32:3 inet static

address 10.66.11.226

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```

::: tip
由于没有这么多客户端，需要配置虚拟IP来模拟海量的客户端。这里配置了4个虚拟IP，后面每个IP使用5w个端口，这样就形成了一台客户端机器可以模拟20w个客户端，后续配上5台客户端机器，最终形成100w个客户TCP端连接，这方面涉及到TCP相关知识，这里就不展开讨论了
:::

### 4.客户端2 IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.227

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:1

iface ens32:1 inet static

address 10.66.11.228

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:2

iface ens32:2 inet static

address 10.66.11.229

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:3

iface ens32:3 inet static

address 10.66.11.230

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```



### 5.客户端3 IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.231

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:1

iface ens32:1 inet static

address 10.66.11.232

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:2

iface ens32:2 inet static

address 10.66.11.233

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:3

iface ens32:3 inet static

address 10.66.11.234

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```



### 6.客户端4 IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.235

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:1

iface ens32:1 inet static

address 10.66.11.236

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:2

iface ens32:2 inet static

address 10.66.11.237

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:3

iface ens32:3 inet static

address 10.66.11.238

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```



### 7.客户端5 IP配置

```bash
auto ens32

iface ens32 inet static

address 10.66.11.239

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:1

iface ens32:1 inet static

address 10.66.11.240

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:2

iface ens32:2 inet static

address 10.66.11.241

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7

auto ens32:3

iface ens32:3 inet static

address 10.66.11.242

netmask 255.255.255.0

gateway 10.66.11.254

dns-nameservers 192.168.12.6 192.168.12.7
```



## 配置JDK环境变量

```bash
sudo vim /etc/profile

export JAVA_HOME=/home/yzh/jdk1.8.0_202

export JRE_HOME=${JAVA_HOME}/jre

export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATH

export JAVA_PATH=${JAVA_HOME}/bin:${JRE_HOME}/bin

export PATH=$PATH:${JAVA_PATH}

source /etc/profile
```



## 操作系统内核参数调整

### 文件句柄修改(不要大于100w,可能无法登录)

修改如下配置

```bash
sudo vim /etc/security/limits.conf
```



- **服务端**

```bash
* soft nofile 1000000
* hard nofile 1000000
```

::: danger
句柄数这个内核参数不要调整过大，否则会导致操作系统崩坏无法启动，前面调整的时候就搞坏过几次，实验Ubuntu16.04这个版本，设置了1000090还是1000009的时候就不行了，大家可以回头试下。有些云平台甚至禁止你修改内核参数，早些年工作的时候让运维修改腾讯云的实例主机内核参数，导致整个实例坏掉，血的教训。我们自己玩的话可以随便搞，投产的话一般不会让一个主机绑定这么多句柄的，一般上10w个就已经非常不错了，分布式的时代，大家都懂。在服务器眼里万物皆句柄，IO、指令操作、网络(TCP/UDP)连接等等，都会占用一个句柄。
:::



- **客户端**

```bash
* soft nofile 300000
* hard nofile 300000
```



### 其他内核参数调整

修改如下配置

```bash
sudo vim /etc/sysctl.conf
```



- **服务端**

  我们自己压测的时候按这个配置来就可以，投产的话就不能这么玩了，需要与运维团队进行评估参数的可行性，一般运维不会让你乱玩的，除非你很有话语权，别到时候搞出幺蛾子，挨打。这套配置是我经过3天压测慢慢调整过的，保持了一周的百万长连接不掉线和服务器良好的运行状态，感觉应该不会有什么大事情(跑着跑着冒烟啥的)。但最终还是需要围绕业务的性质进行调整的，天下没有万能药，有的只是先辈们走过的路，踩过的坑，总结下来的前车之鉴，后车之师，目前市场上的各类云服务器(阿里云/腾讯云/各大厂云)，本质也是他们的内部专家按需调整的一些参数卖的服务器。拿阿里ECS来说，就有普通型、计算型、增强型，网络增强型。一不小心就废话了这么多...

```bash
# 系统最大文件打开数
fs.file-max = 1000000
# 单个用户进程最大文件打开数
fs.nr_open = 1000000
# 全连接队列长度,默认128
net.core.somaxconn = 10240
# 半连接队列长度，当使用sysncookies无效，默认128
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_syncookies = 0
# 网卡数据包队列长度
net.core.netdev_max_backlog = 41960
# time-wait 最大队列长度
net.ipv4.tcp_max_tw_buckets = 300000
# time-wait 是否重新用于新链接以及快速回收
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_timestamps=1
# tcp报文探测时间间隔, 单位s
net.ipv4.tcp_keepalive_intvl = 30
# tcp连接多少秒后没有数据报文时启动探测报文
net.ipv4.tcp_keepalive_time = 900
# 探测次数
net.ipv4.tcp_keepalive_probes = 3
# 保持fin-wait-2 状态多少秒
net.ipv4.tcp_fin_timeout = 15
# 最大孤儿socket数量,一个孤儿socket占用64KB,当socket主动close掉,处于fin-wait1, last-ack
net.ipv4.tcp_max_orphans = 131072
# 每个套接字所允许得最大缓存区大小
net.core.optmem_max = 819200
# 默认tcp数据接受窗口大小
net.core.rmem_default = 262144
net.core.wmem_default = 262144
net.core.rmem_max = 10240000
net.core.wmem_max = 10240000
# tcp栈内存使用第一个值内存下限, 第二个值缓存区应用压力上限, 第三个值内存上限, 单位为page,通常为4kb
net.ipv4.tcp_mem = 786432 4194304 8388608
# 读, 第一个值为socket缓存区分配最小字节, 第二个，第三个分别被rmem_default, rmem_max覆盖
net.ipv4.tcp_rmem = 4096 4096 4206592
# 写, 第一个值为socket缓存区分配最小字节, 第二个，第三个分别被wmem_default, wmem_max覆盖
net.ipv4.tcp_wmem = 4096 4096 4206592
```

- **客户端**

```bash
fs.file-max = 300000
fs.nr_open = 300000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_timestamps=1
net.ipv4.ip_local_port_range= 1025 65535
```



## 统计

服务器统计下长连接个数

```bash
netstat -nat|grep -i "8888"|wc -l
netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
```

 

## 开始压测

- **启动服务器**

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.port.start=8888 -Dserver.port.limit=20 -jar server.jar -server -Xmx8g -Xms8g -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./server_oom.log > ./server.log 2>&1 < /dev/null &
```

::: tip
server.port.limit=20
表示我们要开20个服务对接20客户端机器，一个IP固定了65535个端口，这个是铁定的真理，谁也撼动不了的事实。这里只启动了个jar服务，但内部已经开了20个TCP端口，启动了20个服务，我们利用Netty的主从多线程模型一行代码很简单就可以实现这个过程
:::



- **启动5个客户端**

  client.port.limit=50000

  每个客户端使用5w个端口

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.ip=10.66.11.222 -Dserver.port.start=8888 -Dserver.port.end=8907 -Dclient.ip.pre=10.66.11 -Dclient.ip.start=223 -Dclient.ip.end=226 -Dclient.port.limit=50000 -jar client.jar -server -Xmx2048m -Xms2048m -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./client_oom.log > ./client.log 2>&1 < /dev/null &
```

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.ip=10.66.11.222 -Dserver.port.start=8888 -Dserver.port.end=8907 -Dclient.ip.pre=10.66.11 -Dclient.ip.start=227 -Dclient.ip.end=230 -Dclient.port.limit=50000 -jar client.jar -server -Xmx2048m -Xms2048m -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./client_oom.log > ./client.log 2>&1 < /dev/null &
```

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.ip=10.66.11.222 -Dserver.port.start=8888 -Dserver.port.end=8907 -Dclient.ip.pre=10.66.11 -Dclient.ip.start=231 -Dclient.ip.end=234 -Dclient.port.limit=50000 -jar client.jar -server -Xmx2048m -Xms2048m -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./client_oom.log > ./client.log 2>&1 < /dev/null &
```

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.ip=10.66.11.222 -Dserver.port.start=8888 -Dserver.port.end=8907 -Dclient.ip.pre=10.66.11 -Dclient.ip.start=235 -Dclient.ip.end=238 -Dclient.port.limit=50000 -jar client.jar -server -Xmx2048m -Xms2048m -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./client_oom.log > ./client.log 2>&1 < /dev/null &
```

```bash
nohup java -Dio.netty.leakDetection.level=DISABLED -Dlog.console.print=true -Dserver.ip=10.66.11.222 -Dserver.port.start=8888 -Dserver.port.end=8907 -Dclient.ip.pre=10.66.11 -Dclient.ip.start=239 -Dclient.ip.end=242 -Dclient.port.limit=50000 -jar client.jar -server -Xmx2048m -Xms2048m -XX:+UseG1GC -XX:-RestrictContended -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./client_oom.log > ./client.log 2>&1 < /dev/null &
```



## 压测结果

1. **新客户端不断连接**

   ![单机百万CPU100](http://lsjqn.orochi.press/blog/单机百万CPU100.png)

   ::: tip
   这里们可以看到，我们的服务器满负荷的运行所有核心均以彪满，但内存还是有过剩的，说明百万连接，在TCP的半连接队列与三次握手后的连接队列也只用到了将近3个G左右，整个过程，持续10几分钟左右连接完毕
   :::

   

2. 连接完成后

   ![单机百万连接保持](http://lsjqn.orochi.press/blog/单机百万连接保持.png)

   ::: tip
   我们可以看到服务器已经hold住了998929个客户端连接，压测过程反复执行了N次，基本在这个数值，可以认为已经达标了，没达到100w，是因为服务器本身预留的端口和自身运行会产品额外的句柄消耗。这个数值，挂机了一周左右，没有见丢失连接或者下线的情况
   :::

   

3. 服务器句柄耗完

![单机百万连接过载](http://lsjqn.orochi.press/blog/单机百万连接过载.png)

::: warning
压测完后，已经没有可用的句柄用了，导致指令都无法执行了，指令无法执行，并不代替服务器无法使用了，已经占用句柄的进程们还是在正常工作的，不要谎，内存用完了那才是救不活了，此时CUP 20%左右，内存3G左右，健康的不得了
:::


现在附上客户端与服务端源码

::: tip 源码下载
[netty客户端与服务端源码.zip](http://lsjqn.orochi.press/blog/netty%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%BA%90%E7%A0%81.zip)
:::

至此，整个实验完毕，有兴趣的朋友可以自行测试和交流。
